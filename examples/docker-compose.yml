#
# Contains the full adnexus stack (zookeeper, kafka, zerospike, bidder, crosstalk, db, web, elastic, logstash, simulator)
#
version: '3.5'

services:

  zookeeper:
    image: zookeeper:3.5
    ports:
      - '2181:2181'
    networks:
#      - r4f_control
      - r4f_net

  kafka:
    image: wurstmeister/kafka
    environment:
      KAFKA_ADVERTISED_HOST_NAME: kafka
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'false'
      KAFKA_CREATE_TOPICS: bids:1:1,wins:1:1,requests:1:1,clicks:1:1,pixels:1:1,videoevents:1:1,postbackevents:1:1,status:1:1,reasons:1:1,logs:1:1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
    ports:
      - '9092:9092'
    depends_on:
      - zookeeper
    networks:
      # - r4f_kafka
      # - r4f_control
      - r4f_net
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock

  zerospike:
    image: adnexus/zerospike
    environment:
      BROKERLIST: "kafka:9092"
    ports:
      - "6000:6000"
      - "6001:6001"
      - "6002:6002"
      - "7001:7001"
    depends_on:
      - kafka
    networks:
      # - r4f_kafka
      # - r4f_control
      - r4f_net
    command: bash -c "sleep 5 && ./wait-for-it.sh kafka:9092 -t 120 && sleep 1; ./zerospike"

  bidder:
    image: adnexus/bidder
    environment:
      # GDPR mode - set to true if operating inside a region that enforces GDPR
      GDPR_MODE: "false"
      # The Kafka setup - all of the channels which to deliver events
      BROKERLIST: "kafka:9092"
      BIDSCHANNEL: "kafka://[$$BROKERLIST]&topic=bids"
      WINSCHANNEL: "kafka://[$$BROKERLIST]&topic=wins"
      REQUESTSCHANNEL: "kafka://[$$BROKERLIST]&topic=requests"
      CLICKSCHANNEL: "kafka://[$$BROKERLIST]&topic=clicks"
      PIXELSCHANNEL: "kafka://[$$BROKERLIST]&topic=pixels"
      VIDEOEVENTSCHANNEL: "kafka://[$$BROKERLIST]&topic=videoevents"
      POSTBACKEVENTSCHANNEL: "kafka://[$$BROKERLIST]&topic=postbackevents"
      STATUSCHANNEL: "kafka://[$$BROKERLIST]&topic=status"
      REASONSCHANNEL: "kafka://[$$BROKERLIST]&topic=reasons"
      LOGCHANNEL: "kafka://[$$BROKERLIST]&topic=logs"
      # If using Amazon S3 to store data, enter configuration settings below
      S3BUCKET: ""
      S3REGION: ""
      S3SECRETKEY: ""
      S3ACCESSKEY: ""
      AWSACCESSKEY: ""
      AWSSECRETKEY: ""
      AWSREGION: ""
      # Enter SSP information below
      GOOGLE_EKEY: ""
      GOOGLE_IKEY: ""
      OPENX_EKEY: ""
      OPENX_IKEY: ""
      ADX_EKEY:   ""
      ADX_IKEY:   ""
      BIDSWITCH_ID: "1234"
      # Enter information about how to access
      PUBSUB: "zerospike"
      EXTERNAL: "http://localhost:8080"
      ADMINPORT: "0"
      ACCOUNTING: "accountingsystem"
      FREQGOV: "false"
      INDEXPAGE: "/index.html"
    ports:
      - "8080:8080"
      - "8155:8155"
      - "7379:7379"
      - "7000:7000"
    depends_on:
      - kafka
      - crosstalk
      - zerospike
    networks:
      # - r4f_kafka
      # - r4f_control
      # - r4f_rtb
      - r4f_net
    command: bash -c "sleep 5 && ./wait-for-it.sh kafka:9092 -t 120 && ./wait-for-it.sh zerospike:6000 -t 120 && sleep 1; ./adnexus"

  # Enable if you'd like to use the bidding simulator to test connections
  simulator:
    image: adnexus/bidder
    environment:
      BIDDER: "bidder:8080"
      WIN:    "10"
      PIXEL:  "95"
      CLICK:  "2"
      SLEEP:  "100"
      SILENT: "-silent"
    networks:
      # - r4f_rtb
      - r4f_net
    command: bash -c "./wait-for-it.sh bidder:8080 -t 120 && sleep 60;  ./load-elastic -host $$BIDDER -win $$WIN -pixel $$PIXEL -click $$CLICK -sleep $$SLEEP"

  crosstalk:
    image: adnexus/crosstalk
    environment:
      REGION: "US"
      GHOST: "elastic"
      AHOST: "elastic"
      BROKERLIST: "kafka:9092"
      PUBSUB: "zerospike"
      CONTROL: "8100"
      JDBC: "jdbc:mysql://db/adnexus?user=adnexus&password=adnexus"
      PASSWORD: "adnexus"
    depends_on:
      - kafka
      - zerospike
      - elastic
      - db
    networks:
      # - r4f_kafka
      # - r4f_control
      - r4f_net

  db:
    image: mysql:5.7
    volumes:
      - db_data:/var/lib/mysql
    ports:
      - '3306:3306'
    restart: always
    environment:
      - MYSQL_ROOT_PASSWORD=adnexus
      - MYSQL_DATABASE=adnexus
      - MYSQL_USER=adnexus
      - MYSQL_PASSWORD=adnexus
    healthcheck:
        test: ["CMD-SHELL", "mysqladmin -h 'localhost' -u root -padnexus ping --silent"]
        interval: 30s
        timeout: 30s
        retries: 3
    networks:
      # - r4f_control
      - r4f_net
    # custom command is necessary to override 'latin' default charset
    command: mysqld --character-set-server=utf8 --collation-server=utf8_general_ci

  web:
    image: adnexus/campaign-manager
    ports:
      - "3000:3000"
    environment:
      - CUSTOMER_NAME=ADNEXUS
      - DB_HOST=db
      - DB_PORT=3306
      - DB_USERNAME=adnexus
      - DB_PASSWORD=adnexus
      - DB_NAME=adnexus
      - ELASTICSEARCH_ENABLE=true
      - ELASTICSEARCH_HOST=elastic:9200
      - ELASTICSEARCH_KIBANA_URL=http://kibana:5601/
      - RTB_CROSSTALK_REGION_HOSTS={"US" => "crosstalk"}
    depends_on:
      - db
    networks:
      # - r4f_control
      - r4f_net
    command: bundle exec rails s -p 3000 -b '0.0.0.0'

  elastic:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.2.0
    ports:
      - "9200:9200"
      - "9300:9300"
    environment:
      - discovery.type=single-node
      - "ES_JAVA_OPTS=-Xms1g -Xmx1g"
    depends_on:
      - db
    healthcheck:
        test: ["CMD-SHELL", "curl --silent --fail localhost:9200/_cluster/health || exit 1"]
        interval: 30s
        timeout: 30s
        retries: 3
    volumes:
      - esdata1:/usr/share/elasticsearch/data
    networks:
      # - r4f_kafka
      # - r4f_control
      - r4f_net

  logstash:
    image: docker.elastic.co/logstash/logstash:7.2.0
    ports:
      - "5044:5044"
    environment:
      - "XPACK_MONITORING_ELASTICSEARCH_URL=http://elastic:9200"
      - "XPACK_MONITORING_ENABLED=true"
      - "LS_JAVA_OPTS=-Xmx1g"
    networks:
      # - r4f_kafka
      # - r4f_control
      - r4f_net
    volumes:
      - "./logstash:/usr/share/logstash/pipeline"

  kibana:
    image: docker.elastic.co/kibana/kibana:7.2.0
    environment:
      - SERVER_NAME=elastic
      - ELASTICSEARCH_URL=http://elastic:9200
    ports:
      - "5601:5601"
    networks:
      # - r4f_control
      - r4f_net

volumes:
  db_data: {}
  esdata1:
    driver: local

networks:
  # r4f_rtb:
  # r4f_control:
  # r4f_kafka:
  r4f_net:
